[["index.html", "RTI Take Home Assignment Chapter 1 SQL Data Consolidation", " RTI Take Home Assignment Louise Lindegaard 2022-02-07 Chapter 1 SQL Data Consolidation Main objective: Select all variables from the records table and join them with all other tables to consolidate 9 tables into 1 â€“ The select statement contains 2 data cleaning steps: 1. Remove redundant columns 2. Rename variables to logical names -- The select statement contains 2 data cleaning steps: 1. Remove redundant columns 2. Rename variables to logical names SELECT r.id as id, over_50k, age, education_num, capital_gain, capital_loss, hours_week, workclass_id, w.name as workclass, education_level_id, e.name as education_level, marital_status_id, m.name as marital_status, occupation_id, o.name as occupation, relationship_id, rel.name as relationship, race_id, races.name as race, sex_id, s.name as sex, country_id, c.name as country FROM records as r -- The left join includes all observations from the records table LEFT JOIN countries as c ON r.country_id = c.id LEFT JOIN education_levels as e ON r.education_level_id = e.id LEFT JOIN marital_statuses as m ON r.marital_status_id = m.id LEFT JOIN occupations as o ON r.occupation_id = o.id LEFT JOIN races ON r.race_id = races.id LEFT JOIN relationships as rel ON r.relationship_id = rel.id LEFT JOIN sexes as s ON r.sex_id = s.id LEFT JOIN workclasses as w ON r.workclass_id = w.id; -- Per instruction, the above statement was exported to CSV "],["variable-cleaning-and-formating.html", "Chapter 2 Variable Cleaning and Formating 2.1 Import data and libraries into R 2.2 Data Cleaning 2.3 Variable binning 2.4 Check for Quasi Complete Separation 2.5 Split data into training, validation and test 2.6 Exploratory Statistics on Training Data", " Chapter 2 Variable Cleaning and Formating 2.1 Import data and libraries into R census = read.csv(&#39;exercise01_consolidated.csv&#39;) library(ggplot2) library(InformationValue) library(gmodels) library(DescTools) library(vcd) library(vcdExtra) library(stats) library(mgcv) library(car) library(dplyr) library(ROCR) library(caret) library(mgcv) library(xgboost) library(optbin) library(pROC) 2.2 Data Cleaning #Exploring data types for (x in 1:23) { print(colnames(census[x])) print(class(census[,x])) } # Set ordinal/ nominal variables as a factor (less than 20 levels) col_names &lt;- sapply(census, function(col) length(unique(col)) &lt; 20) census[ , col_names] &lt;- lapply(census[ , col_names] , factor) ## Check for NA Values (represented with &quot;?&quot;) in each variable sapply(census, function(x) any(x == &quot;?&quot;)) # NA values are only in categorical variables - will explore binning options below ## Data looks very clean, ready to start exploring 2.3 Variable binning ## Visualize data and explore each variable hist(census$age) # mostly normal with slight skew hist(census$capital_gain) # Zero Inflated hist(census$capital_loss) # Zero Inflated hist(census$hours_week) # Heavily inflated at 40 hours table(census$education_level) # Lots of categories, check for quasi-complete separation later ## Explore zero inflated variables colSums(census==0)/nrow(census)*100 # 91.7 % Capital Gain = 0 and 95.3 % capital loss = 0 # Bin to binary variable: census$capital_gain_indicator = ifelse(census$capital_gain == 0, 0, 1) census$capital_loss_indicator = ifelse(census$capital_loss == 0, 0, 1) # Bin the working hours variable based on inflation at 40 hours census$hours_week_bin[census$hours_week &lt; 40] = 0 census$hours_week_bin[census$hours_week &gt; 40] = 2 census$hours_week_bin[census$hours_week == 40] = 1 # Factorize census$hours_week_bin = factor(census$hours_week_bin) ## Explore country variable table(census$country) # 90% in US, will create binary variable instead for simplicity census$country_bin = ifelse(census$country == &quot;United-States&quot;, 1, 0) # Explore only normal continuous variable for linear relationship gam.age &lt;- gam(over_50k ~ s(age), data = census, family = binomial(link = &#39;logit&#39;), method = &#39;REML&#39;) summary(gam.age) plot(gam.age) # age has non-linear relationship with logit- bin this variable using optbin optbin(census$age, numbin = 4) # Upper inclusive limits of ideal splits is 29, 41, 55, 90 census$age_bin[census$age &lt;= 29] = 0 census$age_bin[census$age &gt; 29 &amp; census$age &lt;= 41] = 1 census$age_bin[census$age &gt; 41 &amp; census$age &lt;= 55] = 2 census$age_bin[census$age &gt; 55] = 3 census$age_bin = factor(census$age_bin) # Remove redundant variables (including education number and relationship to householder) census = census[,c(&#39;id&#39;, &#39;over_50k&#39;, &#39;age_bin&#39;, &#39;capital_gain_indicator&#39;, &#39;capital_loss_indicator&#39;, &#39;hours_week_bin&#39;, &#39;workclass&#39;, &#39;education_level&#39;, &#39;marital_status&#39;, &#39;occupation&#39;, &#39;race&#39;, &#39;sex&#39;, &#39;country_bin&#39; )] 2.4 Check for Quasi Complete Separation # This loop will print out the column name for any cross table that contains zeros (separation) or &lt; 5 observations for (i in 1:13) { x = table(census[, i], census$over_50k) for (k in 1:length(x)) { if (x[k] &lt;= 5) { print(c(names(census)[i], names(census$over_50k))) break } } } # Workclass contains quasi complete separation CrossTable(census$workclass, census$over_50k) # Collapse the never worked and without pay categories with missing as this is the most similar split census = census %&gt;% mutate(workclass = as.character(workclass), workclass = if_else(workclass == &#39;Never-worked&#39; | workclass == &#39;Without-pay&#39; | workclass == &#39;?&#39;, &#39;Unknown&#39;, workclass), workclass = factor(workclass)) # Collapse education levels containing &lt;5 observations: pre-school and 1-4th grade census = census %&gt;% mutate(education_level = as.character(education_level), education_level = if_else(education_level == &#39;Preschool&#39; | education_level == &#39;1st-4th&#39;, &#39;Early-Ed&#39;, education_level), education_level = factor(education_level)) CrossTable(census$occupation, census$over_50k) # Collapse armed-forces with Protective-serv, and Priv-house-serv with Handlers-cleaners census = census %&gt;% mutate(occupation = as.character(occupation), occupation = if_else(occupation == &#39;Armed-Forces&#39;, &#39;Protective-serv&#39;, occupation), occupation = if_else(occupation == &#39;Priv-house-serv&#39;, &#39;Handlers-cleaners&#39;, occupation), occupation = factor(occupation)) CrossTable(census$occupation, census$over_50k) 2.5 Split data into training, validation and test 2.6 Exploratory Statistics on Training Data "],["develop-logistic-regression-model.html", "Chapter 3 Develop Logistic Regression Model 3.1 Check for issues with multi-collinearity 3.2 Variable Selection 3.3 Create Logistic Regression 3.4 Evaluate logistic regression 3.5 Test training cut off on validation", " Chapter 3 Develop Logistic Regression Model 3.1 Check for issues with multi-collinearity 3.2 Variable Selection # Stepwise selection to select relevant variables full.model &lt;- glm(over_50k ~ ., data=train[,2:13], family = binomial(link = &quot;logit&quot;)) empty.model &lt;- glm(over_50k ~ 1, data=train[,2:13], family = binomial(link = &quot;logit&quot;)) step.model &lt;- step(empty.model, scope = list(lower=formula(empty.model), upper=formula(full.model)), direction = &quot;both&quot;) ## Start: AIC=37629.8 ## over_50k ~ 1 ## ## Df Deviance AIC ## + marital_status 6 30139 30153 ## + education_level 14 33160 33190 ## + occupation 12 33394 33420 ## + age_bin 3 33888 33896 ## + hours_week_bin 2 35158 35164 ## + capital_gain_indicator 1 35581 35585 ## + sex 1 35860 35864 ## + workclass 6 36615 36629 ## + capital_loss_indicator 1 37067 37071 ## + race 4 37230 37240 ## + country_bin 1 37595 37599 ## &lt;none&gt; 37628 37630 ## ## Step: AIC=30152.84 ## over_50k ~ marital_status ## ## Df Deviance AIC ## + education_level 14 26020 26062 ## + occupation 12 26777 26815 ## + capital_gain_indicator 1 28648 28664 ## + age_bin 3 28887 28907 ## + hours_week_bin 2 29011 29029 ## + workclass 6 29592 29618 ## + capital_loss_indicator 1 29754 29770 ## + race 4 30020 30042 ## + sex 1 30079 30095 ## + country_bin 1 30088 30104 ## &lt;none&gt; 30139 30153 ## - marital_status 6 37628 37630 ## ## Step: AIC=26062.32 ## over_50k ~ marital_status + education_level ## ## Df Deviance AIC ## + capital_gain_indicator 1 24905 24949 ## + occupation 12 25083 25149 ## + age_bin 3 25147 25195 ## + hours_week_bin 2 25313 25359 ## + workclass 6 25717 25771 ## + capital_loss_indicator 1 25784 25828 ## + sex 1 25946 25990 ## + race 4 25967 26017 ## + country_bin 1 25979 26023 ## &lt;none&gt; 26020 26062 ## - education_level 14 30139 30153 ## - marital_status 6 33160 33190 ## ## Step: AIC=24948.58 ## over_50k ~ marital_status + education_level + capital_gain_indicator ## ## Df Deviance AIC ## + occupation 12 24014 24082 ## + age_bin 3 24090 24140 ## + hours_week_bin 2 24221 24269 ## + capital_loss_indicator 1 24559 24605 ## + workclass 6 24624 24680 ## + sex 1 24833 24879 ## + race 4 24856 24908 ## + country_bin 1 24871 24917 ## &lt;none&gt; 24905 24949 ## - capital_gain_indicator 1 26020 26062 ## - education_level 14 28648 28664 ## - marital_status 6 31633 31665 ## ## Step: AIC=24082.22 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation ## ## Df Deviance AIC ## + age_bin 3 23305 23379 ## + hours_week_bin 2 23518 23590 ## + capital_loss_indicator 1 23696 23766 ## + workclass 6 23874 23954 ## + sex 1 23954 24024 ## + race 4 23983 24059 ## + country_bin 1 23996 24066 ## &lt;none&gt; 24014 24082 ## - occupation 12 24905 24949 ## - capital_gain_indicator 1 25083 25149 ## - education_level 14 25561 25601 ## - marital_status 6 30028 30084 ## ## Step: AIC=23378.92 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin ## ## Df Deviance AIC ## + hours_week_bin 2 22858 22936 ## + capital_loss_indicator 1 23010 23086 ## + workclass 6 23167 23253 ## + sex 1 23261 23337 ## + race 4 23272 23354 ## + country_bin 1 23289 23365 ## &lt;none&gt; 23305 23379 ## - age_bin 3 24014 24082 ## - occupation 12 24090 24140 ## - capital_gain_indicator 1 24318 24390 ## - education_level 14 24722 24768 ## - marital_status 6 27781 27843 ## ## Step: AIC=22936.3 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin ## ## Df Deviance AIC ## + capital_loss_indicator 1 22579 22659 ## + workclass 6 22752 22842 ## + race 4 22835 22921 ## + country_bin 1 22847 22927 ## + sex 1 22850 22930 ## &lt;none&gt; 22858 22936 ## - hours_week_bin 2 23305 23379 ## - occupation 12 23496 23550 ## - age_bin 3 23518 23590 ## - capital_gain_indicator 1 23846 23922 ## - education_level 14 24166 24216 ## - marital_status 6 27076 27142 ## ## Step: AIC=22658.66 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator ## ## Df Deviance AIC ## + workclass 6 22473 22565 ## + race 4 22558 22646 ## + country_bin 1 22569 22651 ## + sex 1 22570 22652 ## &lt;none&gt; 22579 22659 ## - capital_loss_indicator 1 22858 22936 ## - hours_week_bin 2 23010 23086 ## - occupation 12 23199 23255 ## - age_bin 3 23215 23289 ## - capital_gain_indicator 1 23661 23739 ## - education_level 14 23826 23878 ## - marital_status 6 26740 26808 ## ## Step: AIC=22564.56 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass ## ## Df Deviance AIC ## + race 4 22451 22551 ## + country_bin 1 22462 22556 ## + sex 1 22466 22560 ## &lt;none&gt; 22473 22565 ## - workclass 6 22579 22659 ## - capital_loss_indicator 1 22752 22842 ## - hours_week_bin 2 22873 22961 ## - occupation 12 23031 23099 ## - age_bin 3 23110 23196 ## - capital_gain_indicator 1 23537 23627 ## - education_level 14 23731 23795 ## - marital_status 6 26627 26707 ## ## Step: AIC=22550.61 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass + race ## ## Df Deviance AIC ## + country_bin 1 22443 22545 ## + sex 1 22445 22547 ## &lt;none&gt; 22451 22551 ## - race 4 22473 22565 ## - workclass 6 22558 22646 ## - capital_loss_indicator 1 22727 22825 ## - hours_week_bin 2 22842 22938 ## - occupation 12 23000 23076 ## - age_bin 3 23087 23181 ## - capital_gain_indicator 1 23515 23613 ## - education_level 14 23697 23769 ## - marital_status 6 26528 26616 ## ## Step: AIC=22545.08 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass + race + country_bin ## ## Df Deviance AIC ## + sex 1 22437 22541 ## &lt;none&gt; 22443 22545 ## - country_bin 1 22451 22551 ## - race 4 22462 22556 ## - workclass 6 22551 22641 ## - capital_loss_indicator 1 22718 22818 ## - hours_week_bin 2 22832 22930 ## - occupation 12 22986 23064 ## - age_bin 3 23078 23174 ## - capital_gain_indicator 1 23505 23605 ## - education_level 14 23683 23757 ## - marital_status 6 26525 26615 ## ## Step: AIC=22541.19 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass + race + country_bin + sex ## ## Df Deviance AIC ## &lt;none&gt; 22437 22541 ## - sex 1 22443 22545 ## - country_bin 1 22445 22547 ## - race 4 22455 22551 ## - workclass 6 22544 22636 ## - capital_loss_indicator 1 22712 22814 ## - hours_week_bin 2 22798 22898 ## - occupation 12 22984 23064 ## - age_bin 3 23066 23164 ## - capital_gain_indicator 1 23499 23601 ## - education_level 14 23665 23741 ## - marital_status 6 25744 25836 # Forward selection to select two-variable interactions # First: double check interactions for quasi complete separation table(train$over_50k, train$hours_week_bin, train$occupation) ## , , = ? ## ## ## 0 1 2 ## 0 940 642 187 ## 1 74 70 52 ## ## , , = Adm-clerical ## ## ## 0 1 2 ## 0 1033 1906 437 ## 1 89 311 150 ## ## , , = Craft-repair ## ## ## 0 1 2 ## 0 396 2024 903 ## 1 36 547 396 ## ## , , = Exec-managerial ## ## ## 0 1 2 ## 0 377 1056 833 ## 1 111 703 1228 ## ## , , = Farming-fishing ## ## ## 0 1 2 ## 0 202 309 403 ## 1 5 29 88 ## ## , , = Handlers-cleaners ## ## ## 0 1 2 ## 0 481 802 233 ## 1 8 62 24 ## ## , , = Machine-op-inspct ## ## ## 0 1 2 ## 0 223 1311 355 ## 1 5 179 82 ## ## , , = Other-service ## ## ## 0 1 2 ## 0 1598 1289 385 ## 1 40 58 46 ## ## , , = Prof-specialty ## ## ## 0 1 2 ## 0 641 1019 715 ## 1 252 714 953 ## ## , , = Protective-serv ## ## ## 0 1 2 ## 0 74 292 110 ## 1 8 123 94 ## ## , , = Sales ## ## ## 0 1 2 ## 0 1003 950 850 ## 1 83 313 627 ## ## , , = Tech-support ## ## ## 0 1 2 ## 0 166 415 137 ## 1 39 160 90 ## ## , , = Transport-moving ## ## ## 0 1 2 ## 0 199 631 480 ## 1 20 119 194 table(train$over_50k, train$race, train$country_bin) # Quasi complete separation!! ## , , = 0 ## ## ## Amer-Indian-Eskimo Asian-Pac-Islander Black Other White ## 0 11 542 268 127 1848 ## 1 1 207 34 20 442 ## ## , , = 1 ## ## ## Amer-Indian-Eskimo Asian-Pac-Islander Black Other White ## 0 273 228 2614 119 19977 ## 1 30 72 362 15 6999 table(train$over_50k, train$sex, train$capital_gain_indicator) ## , , = 0 ## ## ## Female Male ## 0 9683 15252 ## 1 939 5496 ## ## , , = 1 ## ## ## Female Male ## 0 381 691 ## 1 278 1469 # Build main model with stepwise selected variables main.model &lt;- glm(over_50k ~ marital_status + education_level + capital_gain_indicator + occupation + hours_week_bin + age_bin + capital_loss_indicator + workclass + country_bin + race, data = train, family = binomial(link = &quot;logit&quot;)) # Build model with interactions of interest int.model &lt;- glm(over_50k ~ marital_status + education_level + capital_gain_indicator + occupation + hours_week_bin + age_bin + capital_loss_indicator + workclass + country_bin + race + hours_week_bin*occupation + sex*capital_gain_indicator, data = train, family = binomial(link = &quot;logit&quot;)) # Forward selection for.model &lt;- step(main.model, scope = list(lower=formula(main.model), upper=formula(int.model)), direction = &quot;forward&quot;) ## Start: AIC=22545.08 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race ## ## Df Deviance AIC ## + occupation:hours_week_bin 24 22390 22540 ## + sex 1 22437 22541 ## &lt;none&gt; 22443 22545 ## ## Step: AIC=22539.76 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race + occupation:hours_week_bin ## ## Df Deviance AIC ## + sex 1 22383 22535 ## &lt;none&gt; 22390 22540 ## ## Step: AIC=22535.35 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race + sex + occupation:hours_week_bin ## ## Df Deviance AIC ## &lt;none&gt; 22383 22535 ## + capital_gain_indicator:sex 1 22383 22537 # Final model: # over_50k ~ marital_status + education_level + capital_gain_indicator + # occupation + hours_week_bin + age_bin + capital_loss_indicator + # workclass + country_bin + race + occupation*hours_week_bin 3.3 Create Logistic Regression # GLM with binomial logit link logit.model &lt;- glm(over_50k ~ marital_status + education_level + capital_gain_indicator + occupation + hours_week_bin + age_bin + capital_loss_indicator + workclass + country_bin + race + occupation*hours_week_bin, data = train, family = binomial(link = &quot;logit&quot;)) summary(logit.model) ## ## Call: ## glm(formula = over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race + occupation * hours_week_bin, ## family = binomial(link = &quot;logit&quot;), data = train) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.8286 -0.5061 -0.2020 -0.0499 3.6679 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -6.831206 0.938285 -7.281 3.33e-13 *** ## marital_statusMarried-AF-spouse 2.986659 0.497870 5.999 1.99e-09 *** ## marital_statusMarried-civ-spouse 2.292346 0.059917 38.259 &lt; 2e-16 *** ## marital_statusMarried-spouse-absent 0.222188 0.207847 1.069 0.285072 ## marital_statusNever-married -0.178810 0.077059 -2.320 0.020318 * ## marital_statusSeparated -0.068608 0.151761 -0.452 0.651211 ## marital_statusWidowed 0.233976 0.138564 1.689 0.091300 . ## education_level11th -0.077062 0.216688 -0.356 0.722113 ## education_level12th 0.583845 0.252680 2.311 0.020855 * ## education_level5th-6th -0.147566 0.292611 -0.504 0.614045 ## education_level7th-8th -0.369917 0.229021 -1.615 0.106265 ## education_level9th -0.128730 0.253854 -0.507 0.612081 ## education_levelAssoc-acdm 1.535057 0.176804 8.682 &lt; 2e-16 *** ## education_levelAssoc-voc 1.312912 0.170999 7.678 1.62e-14 *** ## education_levelBachelors 2.037348 0.159922 12.740 &lt; 2e-16 *** ## education_levelDoctorate 3.009879 0.209866 14.342 &lt; 2e-16 *** ## education_levelEarly-Ed -0.958737 0.468309 -2.047 0.040635 * ## education_levelHS-grad 0.875185 0.156189 5.603 2.10e-08 *** ## education_levelMasters 2.388668 0.169043 14.131 &lt; 2e-16 *** ## education_levelProf-school 3.089082 0.199522 15.482 &lt; 2e-16 *** ## education_levelSome-college 1.227385 0.158263 7.755 8.81e-15 *** ## capital_gain_indicator 1.728841 0.054839 31.526 &lt; 2e-16 *** ## occupationAdm-clerical 0.540457 0.896058 0.603 0.546409 ## occupationCraft-repair 0.153790 0.909201 0.169 0.865680 ## occupationExec-managerial 0.875722 0.898277 0.975 0.329614 ## occupationFarming-fishing -1.038040 1.008076 -1.030 0.303139 ## occupationHandlers-cleaners -0.796331 0.971819 -0.819 0.412545 ## occupationMachine-op-inspct -0.759718 0.994069 -0.764 0.444718 ## occupationOther-service -0.158549 0.904909 -0.175 0.860915 ## occupationProf-specialty 0.941148 0.893684 1.053 0.292290 ## occupationProtective-serv -0.006456 0.992684 -0.007 0.994811 ## occupationSales 0.522804 0.898595 0.582 0.560700 ## occupationTech-support 1.119201 0.916606 1.221 0.222076 ## occupationTransport-moving 0.125140 0.912263 0.137 0.890892 ## hours_week_bin1 0.762878 0.205619 3.710 0.000207 *** ## hours_week_bin2 1.249429 0.242599 5.150 2.60e-07 *** ## age_bin1 1.044658 0.059929 17.432 &lt; 2e-16 *** ## age_bin2 1.473089 0.061865 23.811 &lt; 2e-16 *** ## age_bin3 1.223073 0.072499 16.870 &lt; 2e-16 *** ## capital_loss_indicator 1.126312 0.068570 16.426 &lt; 2e-16 *** ## workclassLocal-gov -0.680749 0.107648 -6.324 2.55e-10 *** ## workclassPrivate -0.404421 0.089348 -4.526 6.00e-06 *** ## workclassSelf-emp-inc -0.228541 0.116617 -1.960 0.050024 . ## workclassSelf-emp-not-inc -0.816660 0.105372 -7.750 9.17e-15 *** ## workclassState-gov -0.766890 0.117979 -6.500 8.02e-11 *** ## workclassUnknown -0.599369 0.881418 -0.680 0.496501 ## country_bin 0.181470 0.067343 2.695 0.007044 ** ## raceAsian-Pac-Islander 0.697452 0.251725 2.771 0.005594 ** ## raceBlack 0.612091 0.237392 2.578 0.009926 ** ## raceOther 0.765299 0.323418 2.366 0.017968 * ## raceWhite 0.782244 0.228531 3.423 0.000620 *** ## occupationAdm-clerical:hours_week_bin1 -0.362471 0.253838 -1.428 0.153303 ## occupationCraft-repair:hours_week_bin1 0.083620 0.287675 0.291 0.771301 ## occupationExec-managerial:hours_week_bin1 -0.035255 0.253196 -0.139 0.889260 ## occupationFarming-fishing:hours_week_bin1 0.447424 0.570564 0.784 0.432936 ## occupationHandlers-cleaners:hours_week_bin1 0.364163 0.467594 0.779 0.436096 ## occupationMachine-op-inspct:hours_week_bin1 0.604546 0.521029 1.160 0.245929 ## occupationOther-service:hours_week_bin1 -0.690803 0.305468 -2.261 0.023731 * ## occupationProf-specialty:hours_week_bin1 -0.124899 0.236012 -0.529 0.596663 ## occupationProtective-serv:hours_week_bin1 0.974678 0.505473 1.928 0.053824 . ## occupationSales:hours_week_bin1 -0.161740 0.259686 -0.623 0.533395 ## occupationTech-support:hours_week_bin1 -0.552405 0.326985 -1.689 0.091145 . ## occupationTransport-moving:hours_week_bin1 -0.126269 0.351818 -0.359 0.719668 ## occupationAdm-clerical:hours_week_bin2 -0.349181 0.299157 -1.167 0.243123 ## occupationCraft-repair:hours_week_bin2 -0.042651 0.318005 -0.134 0.893306 ## occupationExec-managerial:hours_week_bin2 0.069903 0.282509 0.247 0.804570 ## occupationFarming-fishing:hours_week_bin2 0.399728 0.556985 0.718 0.472965 ## occupationHandlers-cleaners:hours_week_bin2 -0.010766 0.522460 -0.021 0.983559 ## occupationMachine-op-inspct:hours_week_bin2 0.518360 0.547075 0.948 0.343379 ## occupationOther-service:hours_week_bin2 -0.319017 0.347004 -0.919 0.357914 ## occupationProf-specialty:hours_week_bin2 -0.528663 0.269164 -1.964 0.049519 * ## occupationProtective-serv:hours_week_bin2 0.844580 0.533124 1.584 0.113146 ## occupationSales:hours_week_bin2 -0.082531 0.285482 -0.289 0.772511 ## occupationTech-support:hours_week_bin2 -0.389574 0.372599 -1.046 0.295765 ## occupationTransport-moving:hours_week_bin2 -0.027486 0.370601 -0.074 0.940878 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 37628 on 34188 degrees of freedom ## Residual deviance: 22390 on 34114 degrees of freedom ## AIC: 22540 ## ## Number of Fisher Scoring iterations: 7 3.4 Evaluate logistic regression View Coefficient of Discrimination (R2) # Get coefficient of discrimination (R2) train$p_hat = predict(logit.model, type = &#39;response&#39;) p1 = train$p_hat[train$over_50k == 1] p0 = train$p_hat[train$over_50k == 0] coef_discrim = mean(p1) - mean(p0) print(coef_discrim) ## [1] 0.4280567 # Coeff of discrimination = 0.422 # Get proportions of non-buy and buy prop0 = 26037/34189 prop1 = 8152/34189 # Plot probabilities as density plot ggplot(train, aes(p_hat, fill = over_50k)) + geom_density(alpha = 0.7) + labs(x = &quot;Predicted Probability&quot;, y = &quot;Density&quot;, fill = &quot;Outcome&quot;, title = paste(&quot;Coefficient of Discrimination = &quot;, round(coef_discrim, 3), sep = &quot;&quot;))+ scale_fill_manual( values = c(&quot;royalblue&quot;,&quot;skyblue&quot;), labels=c(&quot;Not Over 50k&quot;, &quot;Over 50k&quot;))+ theme_classic() Determine optimal cut-off # Iterate through cut-off values to determine optimal cut-off train$p_hat &lt;- predict(logit.model, type = &quot;response&quot;) youden &lt;- NULL cutoff &lt;- NULL for(i in 1:49){ cutoff = c(cutoff, i/50) youden &lt;- c(youden, youdensIndex(train$over_50k, train$p_hat, threshold = i/50)) } # Print table with lowest Youdens at the top of the list ctable &lt;- data.frame(cutoff, youden) print(ctable[order(-youden),]) ## cutoff youden ## 11 0.22 0.639972318 ## 12 0.24 0.638420577 ## 10 0.20 0.635384225 ## 9 0.18 0.633670351 ## 13 0.26 0.630615061 ## 8 0.16 0.630123194 ## 14 0.28 0.628273698 ## 15 0.30 0.624164957 ## 7 0.14 0.621438668 ## 16 0.32 0.616868889 ## 17 0.34 0.607300108 ## 6 0.12 0.607226800 ## 18 0.36 0.594787061 ## 19 0.38 0.588021067 ## 5 0.10 0.587466974 ## 20 0.40 0.580892527 ## 21 0.42 0.570955701 ## 4 0.08 0.559269862 ## 22 0.44 0.551496740 ## 23 0.46 0.540729078 ## 24 0.48 0.530681001 ## 25 0.50 0.520288241 ## 3 0.06 0.519084223 ## 26 0.52 0.503338199 ## 27 0.54 0.489320049 ## 28 0.56 0.476470534 ## 29 0.58 0.465220860 ## 2 0.04 0.453448011 ## 30 0.60 0.452797052 ## 31 0.62 0.433781634 ## 32 0.64 0.419999680 ## 33 0.66 0.405947191 ## 34 0.68 0.381713408 ## 35 0.70 0.359072601 ## 36 0.72 0.338306281 ## 1 0.02 0.334254804 ## 37 0.74 0.319220817 ## 38 0.76 0.295709365 ## 39 0.78 0.271530510 ## 40 0.80 0.244778179 ## 41 0.82 0.219697093 ## 42 0.84 0.198474849 ## 43 0.86 0.169786227 ## 44 0.88 0.142571105 ## 45 0.90 0.119545777 ## 46 0.92 0.093304289 ## 47 0.94 0.068459400 ## 48 0.96 0.036274474 ## 49 0.98 0.007500707 # Confusion matrix for train using Youden&#39;s Index optimal cut off train$classification = ifelse(train$p_hat &gt;= 0.2, 1, 0) confusionMatrix(train$over_50k, factor(train$classification)) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 19792 6215 ## 1 1028 7154 ## ## Accuracy : 0.7881 ## 95% CI : (0.7838, 0.7925) ## No Information Rate : 0.609 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.522 ## ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Sensitivity : 0.9506 ## Specificity : 0.5351 ## Pos Pred Value : 0.7610 ## Neg Pred Value : 0.8744 ## Prevalence : 0.6090 ## Detection Rate : 0.5789 ## Detection Prevalence : 0.7607 ## Balanced Accuracy : 0.7429 ## ## &#39;Positive&#39; Class : 0 ## AUROC # Evaluate model using AUROC train$p_hat &lt;- predict(logit.model, type = &quot;response&quot;) plotROC(train$over_50k, train$p_hat) # 0.902 AUROC 3.5 Test training cut off on validation # Make predictions on validation set validation$p_hat = predict(logit.model, newdata = validation, type = &#39;response&#39;) # Confusion Matrix using Youdens cutoff validation$classification = ifelse(validation$p_hat &gt;= 0.2, 1, 0) confusionMatrix(validation$over_50k, factor(validation$classification)) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 2820 890 ## 1 157 1017 ## ## Accuracy : 0.7856 ## 95% CI : (0.7738, 0.7971) ## No Information Rate : 0.6095 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.5162 ## ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Sensitivity : 0.9473 ## Specificity : 0.5333 ## Pos Pred Value : 0.7601 ## Neg Pred Value : 0.8663 ## Prevalence : 0.6095 ## Detection Rate : 0.5774 ## Detection Prevalence : 0.7596 ## Balanced Accuracy : 0.7403 ## ## &#39;Positive&#39; Class : 0 ## # Get concordance Concordance(validation$over_50k, validation$p_hat) ## $Concordance ## [1] 0.8982296 ## ## $Discordance ## [1] 0.1017704 ## ## $Tied ## [1] -1.387779e-17 ## ## $Pairs ## [1] 4355540 # Evaluate model using AUROC plotROC(validation$over_50k, validation$p_hat) # 0.899 AUROC "],["create-xgboost.html", "Chapter 4 Create XGBoost 4.1 Tuning an XGBoost nrounds parameter - 11 was lowest 4.2 Tuning through caret 4.3 Variable importance 4.4 ROC Curve and AUC", " Chapter 4 Create XGBoost 4.1 Tuning an XGBoost nrounds parameter - 11 was lowest 4.2 Tuning through caret eta = .9 and subsample = .25, max tree depth = 10 4.3 Variable importance xgb &lt;- xgboost(data = train_x, label = train_y, subsample = .25, nrounds = 11, eta = 0.9, max_depth = 10) ## [1] train-rmse:0.342072 ## [2] train-rmse:0.337190 ## [3] train-rmse:0.336265 ## [4] train-rmse:0.335902 ## [5] train-rmse:0.337098 ## [6] train-rmse:0.338788 ## [7] train-rmse:0.338115 ## [8] train-rmse:0.338400 ## [9] train-rmse:0.339944 ## [10] train-rmse:0.340416 ## [11] train-rmse:0.340832 xgb.importance(feature_names = colnames(train_x), model = xgb) ## Feature Gain Cover Frequency ## 1: marital_statusMarried-civ-spouse 0.217319238 0.038625497 0.062700965 ## 2: capital_gain_indicator 0.073511968 0.039745853 0.057234727 ## 3: hours_week_bin2 0.044010166 0.028104221 0.052733119 ## 4: occupationProf-specialty 0.042620406 0.043455023 0.018971061 ## 5: age_bin2 0.038748329 0.037286640 0.047266881 ## 6: occupationExec-managerial 0.037697310 0.033767052 0.023472669 ## 7: education_levelBachelors 0.032417756 0.039602327 0.023794212 ## 8: hours_week_bin1 0.030559028 0.016780702 0.063344051 ## 9: capital_loss_indicator 0.028021400 0.049452032 0.033440514 ## 10: age_bin1 0.027745261 0.017626859 0.058520900 ## 11: sexMale 0.026530122 0.007479392 0.037942122 ## 12: workclassPrivate 0.024251696 0.004946274 0.036334405 ## 13: education_levelHS-grad 0.022511862 0.012018654 0.023151125 ## 14: education_levelMasters 0.020293260 0.052021567 0.016077170 ## 15: workclassLocal-gov 0.019684299 0.028496238 0.023794212 ## 16: marital_statusNever-married 0.018736138 0.023466419 0.030225080 ## 17: country_bin 0.018607542 0.008740060 0.029260450 ## 18: workclassSelf-emp-not-inc 0.017058029 0.015859568 0.021221865 ## 19: education_levelSome-college 0.016670855 0.006624666 0.024758842 ## 20: age_bin3 0.016117402 0.029882223 0.031832797 ## 21: workclassSelf-emp-inc 0.015067372 0.036206985 0.021864952 ## 22: raceBlack 0.013675961 0.003250745 0.020578778 ## 23: education_levelDoctorate 0.013009896 0.034985947 0.011254019 ## 24: occupationCraft-repair 0.012924757 0.020736222 0.012861736 ## 25: raceWhite 0.012784554 0.007987087 0.013504823 ## 26: education_levelProf-school 0.011605566 0.037981774 0.009967846 ## 27: occupationSales 0.011517220 0.026148418 0.010932476 ## 28: occupationTech-support 0.011042786 0.009460901 0.009003215 ## 29: education_levelAssoc-acdm 0.010985122 0.019041764 0.014469453 ## 30: occupationTransport-moving 0.010765858 0.058264927 0.012540193 ## 31: workclassState-gov 0.009823151 0.037771842 0.016077170 ## 32: raceAsian-Pac-Islander 0.009185488 0.013275038 0.016398714 ## 33: occupationAdm-clerical 0.008376341 0.014263650 0.011575563 ## 34: education_levelAssoc-voc 0.008066219 0.029646585 0.011254019 ## 35: education_level7th-8th 0.007288943 0.014969495 0.005787781 ## 36: occupationFarming-fishing 0.006501044 0.008473360 0.008038585 ## 37: occupationMachine-op-inspct 0.006436001 0.005584641 0.007395498 ## 38: occupationProtective-serv 0.005992483 0.032735596 0.008681672 ## 39: occupationOther-service 0.005828102 0.003072945 0.009003215 ## 40: workclassUnknown 0.005285910 0.003351428 0.007395498 ## 41: marital_statusSeparated 0.004648236 0.002407801 0.009324759 ## 42: education_level11th 0.004628037 0.005066236 0.006430868 ## 43: marital_statusMarried-spouse-absent 0.003484768 0.002457071 0.004823151 ## 44: education_level9th 0.003378407 0.015008055 0.003215434 ## 45: occupationHandlers-cleaners 0.002692107 0.004463215 0.003215434 ## 46: marital_statusWidowed 0.002636658 0.002268560 0.005466238 ## 47: education_level5th-6th 0.002371726 0.002780539 0.002572347 ## 48: education_level12th 0.002344314 0.001820846 0.003858521 ## 49: education_levelEarly-Ed 0.001823554 0.004086192 0.002250804 ## 50: raceOther 0.001442406 0.002321043 0.002572347 ## 51: marital_statusMarried-AF-spouse 0.001274949 0.006129824 0.001607717 ## Feature Gain Cover Frequency xgb.ggplot.importance(xgb.importance(feature_names = colnames(train_x), model = xgb)) 4.4 ROC Curve and AUC # get predictions # Prepare data for predict function validation_x &lt;- model.matrix(over_50k ~ ., data = validation)[, 3:53] validation_y &lt;- as.numeric(as.character(validation$over_50k)) p_hat_xgb &lt;- predict(xgb, newdata = validation_x, type = &quot;response&quot;) # create ROC object rocobj &lt;- roc(validation$over_50k, p_hat_xgb) ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases rocobj$auc # to get AUC - 0.816 ## Area under the curve: 0.8287 # create ROC plot with minimal theme ggroc(rocobj, colour = &#39;steelblue&#39;, size = 2) + ggtitle(paste0(&#39;XGBoost Model ROC Curve &#39;, &#39;(AUC = &#39;, round(rocobj$auc, 4), &#39;)&#39;)) + theme_minimal()+ labs(x=&quot;1-Specificity (FPR)&quot;,y=&quot;Sensitivity (TPR)&quot;)+geom_abline(intercept = 1.00, size = 0.5, linetype=&quot;dotted&quot;, color = &quot;red&quot;)+ coord_cartesian(xlim=c(1,0)) "],["conclusion-write-up.html", "Chapter 5 Conclusion / Write Up 5.1 Figure 1 5.2 Final AUROC Chart", " Chapter 5 Conclusion / Write Up Overview The goal of this project is to develop a model that predicts whether individuals, based on census variables, make over $50,000/year. I compared the predictive power of a logistic regression to an XGBoost model using the area under the ROC curve (AUROC). This statistic calculates each models ability to distinguish between people who make above $50,000/year from those who do not. The logistic regression model resulted in the higher AUROC, and was able to better predict who is likely to make above $50,000/year from census data. The final AUROC on the test data was 0.894. Methodology The first two steps were exploring each variable individually and binning continuous variables into categories. Each variable was then tested for quasi-complete separation. This is a problem when a subgroup of the predictor variable perfectly predicts the target variable outcome. Each subgroup with less than 5 observations was collapsed into a new, larger group. The data was split into a 70/20/10 training/validation/test split and each variable was tested for multi-collinearity to ensure no two variables are providing the same information in the model. Stepwise selection was used to identify which variables were important in predicting the target. The 13 important variables were then used in a forward selection process to identify any predictive interactions. For example, the selection process identified changes in the target variables relationship with hours worked each week when looking at different occupations. A logistic regression was built using these variables. The XGBoost was tuned and built using all census variables, and the most important variables were calculated using a gain statistic. Results A simple relationship between marital status and people who make over 50k can be pictured in Figure 1. This figure shows the large majority of people who make over 50k are married to civil spouses. In our census data, 85% of people who make over 50k are married to a civil spouse compared to only 33% of those who do not make over 50k. Furthermore, the XGBoost model found marital status to be the most important variable in predicting the target. The logistic regression was able to better predict people who make over $50,000/year using census variables. I recommend using a logistic regression moving forward to best predict the individuals that make over 50K using census data. Given more time for tuning, you might be able to challenge the predictive power using a future XGBoost model. 5.1 Figure 1 # Add color blind palette cbPalette = c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;) # Plot data ggplot(data = train) + geom_bar(mapping = aes(x = over_50k, fill = marital_status, color =)) + scale_fill_manual(values=cbPalette) + #scale_fill_discrete(labels = c(&quot;Divorced&quot;, &quot;Married- Armed Forces&quot;, &quot;Married- Civil Spouse&quot;, &quot;Married- Spouse Absent&quot;, &quot;Never Married&quot;, &quot;Separated&quot;, &quot;Widowed&quot;)) + labs(title=&quot;Marital Status over Earning Category&quot;, x =&quot;Earning Over 50k (0: No, 1: Yes)&quot;, y = &quot;Frequency&quot;, fill = &quot;Marital Status&quot;) + theme_minimal() 5.2 Final AUROC Chart # Make predictions on validation set test$p_hat = predict(logit.model, newdata = test, type = &#39;response&#39;) # Evaluate model using AUROC plotROC(test$over_50k, test$p_hat) # 0.894 AUROC This repo was initially generated from a bookdown template available here: https://github.com/jtr13/bookdown-template. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
