[["index.html", "RTI Take Home Assignment Chapter 1 SQL Data Consolidation", " RTI Take Home Assignment Louise Lindegaard 2022-02-06 Chapter 1 SQL Data Consolidation Main objective: Select all variables from the records table and join them with all other tables to consolidate 9 tables into 1 â€“ The select statement contains 2 data cleaning steps: 1. Remove redundant columns 2. Rename variables to logical names "],["variable-cleaning-and-formating.html", "Chapter 2 Variable Cleaning and Formating 2.1 Import data and libraries into R 2.2 Data Cleaning 2.3 Variable binning 2.4 Check for Quasi Complete Separation 2.5 Split data into training, validation and test 2.6 Exploratory Statistics on Training Data", " Chapter 2 Variable Cleaning and Formating 2.1 Import data and libraries into R 2.2 Data Cleaning 2.3 Variable binning 2.4 Check for Quasi Complete Separation 2.5 Split data into training, validation and test 2.6 Exploratory Statistics on Training Data "],["develop-logistic-regression-model.html", "Chapter 3 Develop Logistic Regression Model 3.1 Check for issues with multi-collinearity 3.2 Variable Selection 3.3 Create Logistic Regression 3.4 Evaluate logistic regression 3.5 Test training cut off on validation", " Chapter 3 Develop Logistic Regression Model 3.1 Check for issues with multi-collinearity 3.2 Variable Selection # Stepwise selection to select relevant variables full.model &lt;- glm(over_50k ~ ., data=train[,2:13], family = binomial(link = &quot;logit&quot;)) empty.model &lt;- glm(over_50k ~ 1, data=train[,2:13], family = binomial(link = &quot;logit&quot;)) step.model &lt;- step(empty.model, scope = list(lower=formula(empty.model), upper=formula(full.model)), direction = &quot;both&quot;) ## Start: AIC=37650.61 ## over_50k ~ 1 ## ## Df Deviance AIC ## + marital_status 6 30123 30137 ## + occupation 12 33239 33265 ## + education_level 14 33242 33272 ## + age_bin 3 33943 33951 ## + hours_week_bin 2 35187 35193 ## + capital_gain_indicator 1 35592 35596 ## + sex 1 35847 35851 ## + workclass 6 36598 36612 ## + capital_loss_indicator 1 37114 37118 ## + race 4 37242 37252 ## + country_bin 1 37611 37615 ## &lt;none&gt; 37649 37651 ## ## Step: AIC=30137.35 ## over_50k ~ marital_status ## ## Df Deviance AIC ## + education_level 14 26029 26071 ## + occupation 12 26650 26688 ## + capital_gain_indicator 1 28635 28651 ## + age_bin 3 28895 28915 ## + hours_week_bin 2 29023 29041 ## + workclass 6 29552 29578 ## + capital_loss_indicator 1 29763 29779 ## + race 4 29997 30019 ## + sex 1 30063 30079 ## + country_bin 1 30064 30080 ## &lt;none&gt; 30123 30137 ## - marital_status 6 37649 37651 ## ## Step: AIC=26070.84 ## over_50k ~ marital_status + education_level ## ## Df Deviance AIC ## + capital_gain_indicator 1 24929 24973 ## + occupation 12 25004 25070 ## + age_bin 3 25173 25221 ## + hours_week_bin 2 25344 25390 ## + workclass 6 25688 25742 ## + capital_loss_indicator 1 25811 25855 ## + sex 1 25957 26001 ## + race 4 25976 26026 ## + country_bin 1 25989 26033 ## &lt;none&gt; 26029 26071 ## - education_level 14 30123 30137 ## - marital_status 6 33242 33272 ## ## Step: AIC=24973.02 ## over_50k ~ marital_status + education_level + capital_gain_indicator ## ## Df Deviance AIC ## + occupation 12 23953 24021 ## + age_bin 3 24122 24172 ## + hours_week_bin 2 24278 24326 ## + capital_loss_indicator 1 24608 24654 ## + workclass 6 24613 24669 ## + sex 1 24863 24909 ## + race 4 24883 24935 ## + country_bin 1 24897 24943 ## &lt;none&gt; 24929 24973 ## - capital_gain_indicator 1 26029 26071 ## - education_level 14 28635 28651 ## - marital_status 6 31729 31761 ## ## Step: AIC=24021.46 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation ## ## Df Deviance AIC ## + age_bin 3 23249 23323 ## + hours_week_bin 2 23495 23567 ## + capital_loss_indicator 1 23663 23733 ## + workclass 6 23805 23885 ## + sex 1 23900 23970 ## + race 4 23922 23998 ## + country_bin 1 23937 24007 ## &lt;none&gt; 23954 24022 ## - occupation 12 24929 24973 ## - capital_gain_indicator 1 25004 25070 ## - education_level 14 25443 25483 ## - marital_status 6 30007 30063 ## ## Step: AIC=23322.61 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin ## ## Df Deviance AIC ## + hours_week_bin 2 22840 22918 ## + capital_loss_indicator 1 22979 23055 ## + workclass 6 23104 23190 ## + sex 1 23213 23289 ## + race 4 23216 23298 ## + country_bin 1 23235 23311 ## &lt;none&gt; 23249 23323 ## - age_bin 3 23954 24022 ## - occupation 12 24122 24172 ## - capital_gain_indicator 1 24252 24324 ## - education_level 14 24598 24644 ## - marital_status 6 27783 27845 ## ## Step: AIC=22917.82 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin ## ## Df Deviance AIC ## + capital_loss_indicator 1 22583 22663 ## + workclass 6 22727 22817 ## + race 4 22816 22902 ## + country_bin 1 22830 22910 ## + sex 1 22834 22914 ## &lt;none&gt; 22840 22918 ## - hours_week_bin 2 23249 23323 ## - age_bin 3 23495 23567 ## - occupation 12 23565 23619 ## - capital_gain_indicator 1 23815 23891 ## - education_level 14 24083 24133 ## - marital_status 6 27116 27182 ## ## Step: AIC=22663.35 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator ## ## Df Deviance AIC ## + workclass 6 22476 22568 ## + race 4 22560 22648 ## + country_bin 1 22575 22657 ## + sex 1 22578 22660 ## &lt;none&gt; 22583 22663 ## - capital_loss_indicator 1 22840 22918 ## - hours_week_bin 2 22979 23055 ## - age_bin 3 23218 23292 ## - occupation 12 23286 23342 ## - capital_gain_indicator 1 23646 23724 ## - education_level 14 23770 23822 ## - marital_status 6 26803 26871 ## ## Step: AIC=22567.76 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass ## ## Df Deviance AIC ## + race 4 22451 22551 ## + country_bin 1 22466 22560 ## + sex 1 22472 22566 ## &lt;none&gt; 22476 22568 ## - workclass 6 22583 22663 ## - capital_loss_indicator 1 22727 22817 ## - hours_week_bin 2 22842 22930 ## - occupation 12 23100 23168 ## - age_bin 3 23109 23195 ## - capital_gain_indicator 1 23520 23610 ## - education_level 14 23669 23733 ## - marital_status 6 26680 26760 ## ## Step: AIC=22551.26 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass + race ## ## Df Deviance AIC ## + country_bin 1 22444 22546 ## + sex 1 22448 22550 ## &lt;none&gt; 22451 22551 ## - race 4 22476 22568 ## - workclass 6 22560 22648 ## - capital_loss_indicator 1 22703 22801 ## - hours_week_bin 2 22808 22904 ## - occupation 12 23066 23142 ## - age_bin 3 23083 23177 ## - capital_gain_indicator 1 23495 23593 ## - education_level 14 23627 23699 ## - marital_status 6 26570 26658 ## ## Step: AIC=22545.75 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass + race + country_bin ## ## Df Deviance AIC ## + sex 1 22440 22544 ## &lt;none&gt; 22444 22546 ## - country_bin 1 22451 22551 ## - race 4 22466 22560 ## - workclass 6 22553 22643 ## - capital_loss_indicator 1 22694 22794 ## - hours_week_bin 2 22798 22896 ## - occupation 12 23052 23130 ## - age_bin 3 23075 23171 ## - capital_gain_indicator 1 23486 23586 ## - education_level 14 23609 23683 ## - marital_status 6 26567 26657 ## ## Step: AIC=22544.51 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + age_bin + hours_week_bin + capital_loss_indicator + ## workclass + race + country_bin + sex ## ## Df Deviance AIC ## &lt;none&gt; 22440 22544 ## - sex 1 22444 22546 ## - country_bin 1 22448 22550 ## - race 4 22462 22558 ## - workclass 6 22548 22640 ## - capital_loss_indicator 1 22691 22793 ## - hours_week_bin 2 22773 22873 ## - occupation 12 23051 23131 ## - age_bin 3 23066 23164 ## - capital_gain_indicator 1 23482 23584 ## - education_level 14 23597 23673 ## - marital_status 6 25801 25893 # Forward selection to select two-variable interactions # First: double check interactions for quasi complete separation table(train$over_50k, train$hours_week_bin, train$occupation) ## , , = ? ## ## ## 0 1 2 ## 0 961 644 172 ## 1 79 64 49 ## ## , , = Adm-clerical ## ## ## 0 1 2 ## 0 1030 1936 411 ## 1 93 303 140 ## ## , , = Craft-repair ## ## ## 0 1 2 ## 0 436 1955 907 ## 1 39 534 398 ## ## , , = Exec-managerial ## ## ## 0 1 2 ## 0 345 1021 852 ## 1 116 695 1238 ## ## , , = Farming-fishing ## ## ## 0 1 2 ## 0 201 305 424 ## 1 7 27 91 ## ## , , = Handlers-cleaners ## ## ## 0 1 2 ## 0 493 834 233 ## 1 7 62 27 ## ## , , = Machine-op-inspct ## ## ## 0 1 2 ## 0 220 1276 347 ## 1 6 171 91 ## ## , , = Other-service ## ## ## 0 1 2 ## 0 1612 1284 400 ## 1 31 52 45 ## ## , , = Prof-specialty ## ## ## 0 1 2 ## 0 622 1017 734 ## 1 238 751 965 ## ## , , = Protective-serv ## ## ## 0 1 2 ## 0 89 279 113 ## 1 10 116 92 ## ## , , = Sales ## ## ## 0 1 2 ## 0 1008 936 883 ## 1 83 338 590 ## ## , , = Tech-support ## ## ## 0 1 2 ## 0 171 398 135 ## 1 44 163 90 ## ## , , = Transport-moving ## ## ## 0 1 2 ## 0 206 649 459 ## 1 19 116 211 table(train$over_50k, train$race, train$country_bin) # Quasi complete separation!! ## , , = 0 ## ## ## Amer-Indian-Eskimo Asian-Pac-Islander Black Other White ## 0 11 553 263 135 1848 ## 1 1 215 38 16 427 ## ## , , = 1 ## ## ## Amer-Indian-Eskimo Asian-Pac-Islander Black Other White ## 0 284 219 2616 117 19952 ## 1 32 81 358 16 7007 table(train$over_50k, train$sex, train$capital_gain_indicator) ## , , = 0 ## ## ## Female Male ## 0 9799 15126 ## 1 930 5507 ## ## , , = 1 ## ## ## Female Male ## 0 354 719 ## 1 295 1459 # Build main model with stepwise selected variables main.model &lt;- glm(over_50k ~ marital_status + education_level + capital_gain_indicator + occupation + hours_week_bin + age_bin + capital_loss_indicator + workclass + country_bin + race, data = train, family = binomial(link = &quot;logit&quot;)) # Build model with interactions of interest int.model &lt;- glm(over_50k ~ marital_status + education_level + capital_gain_indicator + occupation + hours_week_bin + age_bin + capital_loss_indicator + workclass + country_bin + race + hours_week_bin*occupation + sex*capital_gain_indicator, data = train, family = binomial(link = &quot;logit&quot;)) # Forward selection for.model &lt;- step(main.model, scope = list(lower=formula(main.model), upper=formula(int.model)), direction = &quot;forward&quot;) ## Start: AIC=22545.75 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race ## ## Df Deviance AIC ## + sex 1 22440 22544 ## + occupation:hours_week_bin 24 22395 22545 ## &lt;none&gt; 22444 22546 ## ## Step: AIC=22544.51 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race + sex ## ## Df Deviance AIC ## + capital_gain_indicator:sex 1 22435 22541 ## + occupation:hours_week_bin 24 22391 22543 ## &lt;none&gt; 22440 22544 ## ## Step: AIC=22540.59 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race + sex + capital_gain_indicator:sex ## ## Df Deviance AIC ## + occupation:hours_week_bin 24 22385 22539 ## &lt;none&gt; 22435 22541 ## ## Step: AIC=22538.99 ## over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race + sex + capital_gain_indicator:sex + ## occupation:hours_week_bin # Final model: # over_50k ~ marital_status + education_level + capital_gain_indicator + # occupation + hours_week_bin + age_bin + capital_loss_indicator + # workclass + country_bin + race + occupation*hours_week_bin 3.3 Create Logistic Regression # GLM with binomial logit link logit.model &lt;- glm(over_50k ~ marital_status + education_level + capital_gain_indicator + occupation + hours_week_bin + age_bin + capital_loss_indicator + workclass + country_bin + race + occupation*hours_week_bin, data = train, family = binomial(link = &quot;logit&quot;)) summary(logit.model) ## ## Call: ## glm(formula = over_50k ~ marital_status + education_level + capital_gain_indicator + ## occupation + hours_week_bin + age_bin + capital_loss_indicator + ## workclass + country_bin + race + occupation * hours_week_bin, ## family = binomial(link = &quot;logit&quot;), data = train) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.8349 -0.5040 -0.2002 -0.0493 3.7154 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -5.576331 1.145227 -4.869 1.12e-06 *** ## marital_statusMarried-AF-spouse 2.426322 0.489187 4.960 7.05e-07 *** ## marital_statusMarried-civ-spouse 2.287729 0.059569 38.405 &lt; 2e-16 *** ## marital_statusMarried-spouse-absent 0.410925 0.193671 2.122 0.033857 * ## marital_statusNever-married -0.176661 0.076413 -2.312 0.020783 * ## marital_statusSeparated -0.178487 0.155304 -1.149 0.250442 ## marital_statusWidowed 0.104570 0.145654 0.718 0.472799 ## education_level11th 0.137011 0.206813 0.662 0.507661 ## education_level12th 0.317898 0.265998 1.195 0.232042 ## education_level5th-6th -0.304368 0.300869 -1.012 0.311716 ## education_level7th-8th -0.316740 0.223075 -1.420 0.155642 ## education_level9th -0.243435 0.255358 -0.953 0.340434 ## education_levelAssoc-acdm 1.436238 0.173478 8.279 &lt; 2e-16 *** ## education_levelAssoc-voc 1.273443 0.167125 7.620 2.54e-14 *** ## education_levelBachelors 1.993178 0.155653 12.805 &lt; 2e-16 *** ## education_levelDoctorate 2.843156 0.203915 13.943 &lt; 2e-16 *** ## education_levelEarly-Ed -1.161459 0.542144 -2.142 0.032166 * ## education_levelHS-grad 0.873802 0.151949 5.751 8.89e-09 *** ## education_levelMasters 2.301095 0.164848 13.959 &lt; 2e-16 *** ## education_levelProf-school 3.019939 0.196864 15.340 &lt; 2e-16 *** ## education_levelSome-college 1.205330 0.154143 7.820 5.30e-15 *** ## capital_gain_indicator 1.703117 0.054450 31.279 &lt; 2e-16 *** ## occupationAdm-clerical -0.488649 1.109744 -0.440 0.659701 ## occupationCraft-repair -1.067688 1.122078 -0.952 0.341337 ## occupationExec-managerial -0.214378 1.114547 -0.192 0.847472 ## occupationFarming-fishing -2.015220 1.184885 -1.701 0.088986 . ## occupationHandlers-cleaners -2.118558 1.183973 -1.789 0.073556 . ## occupationMachine-op-inspct -1.691791 1.183805 -1.429 0.152972 ## occupationOther-service -1.571402 1.123344 -1.399 0.161855 ## occupationProf-specialty -0.199504 1.111111 -0.180 0.857503 ## occupationProtective-serv -0.882822 1.171197 -0.754 0.450983 ## occupationSales -0.577339 1.114981 -0.518 0.604597 ## occupationTech-support 0.153923 1.126919 0.137 0.891357 ## occupationTransport-moving -0.928624 1.137952 -0.816 0.414472 ## hours_week_bin1 0.547044 0.208763 2.620 0.008783 ** ## hours_week_bin2 1.248926 0.252918 4.938 7.89e-07 *** ## age_bin1 1.049047 0.059513 17.627 &lt; 2e-16 *** ## age_bin2 1.462869 0.061527 23.776 &lt; 2e-16 *** ## age_bin3 1.190935 0.071894 16.565 &lt; 2e-16 *** ## capital_loss_indicator 1.093910 0.069380 15.767 &lt; 2e-16 *** ## workclassLocal-gov -0.629201 0.105795 -5.947 2.72e-09 *** ## workclassPrivate -0.402754 0.088149 -4.569 4.90e-06 *** ## workclassSelf-emp-inc -0.110969 0.117230 -0.947 0.343844 ## workclassSelf-emp-not-inc -0.775409 0.104261 -7.437 1.03e-13 *** ## workclassState-gov -0.748927 0.118027 -6.345 2.22e-10 *** ## workclassUnknown -1.684980 1.101090 -1.530 0.125947 ## country_bin 0.184352 0.067740 2.721 0.006499 ** ## raceAsian-Pac-Islander 0.685241 0.243118 2.819 0.004824 ** ## raceBlack 0.514510 0.228714 2.250 0.024475 * ## raceOther 0.559238 0.324170 1.725 0.084502 . ## raceWhite 0.725147 0.219302 3.307 0.000944 *** ## occupationAdm-clerical:hours_week_bin1 -0.349248 0.255052 -1.369 0.170899 ## occupationCraft-repair:hours_week_bin1 0.379191 0.284770 1.332 0.183002 ## occupationExec-managerial:hours_week_bin1 0.150745 0.255625 0.590 0.555383 ## occupationFarming-fishing:hours_week_bin1 0.482599 0.527926 0.914 0.360643 ## occupationHandlers-cleaners:hours_week_bin1 0.631767 0.491827 1.285 0.198956 ## occupationMachine-op-inspct:hours_week_bin1 0.568078 0.492663 1.153 0.248879 ## occupationOther-service:hours_week_bin1 -0.311677 0.322716 -0.966 0.334147 ## occupationProf-specialty:hours_week_bin1 0.087321 0.239260 0.365 0.715139 ## occupationProtective-serv:hours_week_bin1 0.703722 0.455836 1.544 0.122636 ## occupationSales:hours_week_bin1 0.121127 0.261702 0.463 0.643478 ## occupationTech-support:hours_week_bin1 -0.369701 0.319599 -1.157 0.247368 ## occupationTransport-moving:hours_week_bin1 -0.112491 0.355171 -0.317 0.751454 ## occupationAdm-clerical:hours_week_bin2 -0.466743 0.308726 -1.512 0.130576 ## occupationCraft-repair:hours_week_bin2 -0.007288 0.321163 -0.023 0.981895 ## occupationExec-managerial:hours_week_bin2 -0.011417 0.291149 -0.039 0.968721 ## occupationFarming-fishing:hours_week_bin2 0.112059 0.513438 0.218 0.827232 ## occupationHandlers-cleaners:hours_week_bin2 0.268138 0.543295 0.494 0.621631 ## occupationMachine-op-inspct:hours_week_bin2 0.326669 0.522225 0.626 0.531621 ## occupationOther-service:hours_week_bin2 -0.128674 0.365494 -0.352 0.724797 ## occupationProf-specialty:hours_week_bin2 -0.444277 0.278970 -1.593 0.111258 ## occupationProtective-serv:hours_week_bin2 0.458701 0.490308 0.936 0.349512 ## occupationSales:hours_week_bin2 -0.286703 0.294634 -0.973 0.330513 ## occupationTech-support:hours_week_bin2 -0.612663 0.371055 -1.651 0.098710 . ## occupationTransport-moving:hours_week_bin2 0.031612 0.378371 0.084 0.933417 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 37649 on 34188 degrees of freedom ## Residual deviance: 22395 on 34114 degrees of freedom ## AIC: 22545 ## ## Number of Fisher Scoring iterations: 7 3.4 Evaluate logistic regression View Coefficient of Discrimination (R2) # Get coefficient of discrimination (R2) train$p_hat = predict(logit.model, type = &#39;response&#39;) p1 = train$p_hat[train$over_50k == 1] p0 = train$p_hat[train$over_50k == 0] coef_discrim = mean(p1) - mean(p0) print(coef_discrim) ## [1] 0.4279329 # Coeff of discrimination = 0.422 # Get proportions of non-buy and buy prop0 = 26037/34189 prop1 = 8152/34189 # Plot probabilities as density plot ggplot(train, aes(p_hat, fill = over_50k)) + geom_density(alpha = 0.7) + labs(x = &quot;Predicted Probability&quot;, y = &quot;Density&quot;, fill = &quot;Outcome&quot;, title = paste(&quot;Coefficient of Discrimination = &quot;, round(coef_discrim, 3), sep = &quot;&quot;))+ scale_fill_manual( values = c(&quot;royalblue&quot;,&quot;skyblue&quot;), labels=c(&quot;Not Over 50k&quot;, &quot;Over 50k&quot;))+ theme_classic() Determine optimal cut-off # Iterate through cut-off values to determine optimal cut-off train$p_hat &lt;- predict(logit.model, type = &quot;response&quot;) youden &lt;- NULL cutoff &lt;- NULL for(i in 1:49){ cutoff = c(cutoff, i/50) youden &lt;- c(youden, youdensIndex(train$over_50k, train$p_hat, threshold = i/50)) } # Print table with lowest Youdens at the top of the list ctable &lt;- data.frame(cutoff, youden) print(ctable[order(-youden),]) ## cutoff youden ## 12 0.24 0.642192079 ## 11 0.22 0.641750839 ## 10 0.20 0.638322751 ## 9 0.18 0.636553746 ## 13 0.26 0.635833378 ## 8 0.16 0.631240846 ## 14 0.28 0.628063085 ## 15 0.30 0.623418634 ## 7 0.14 0.619972692 ## 16 0.32 0.619408056 ## 17 0.34 0.610475502 ## 6 0.12 0.607871652 ## 18 0.36 0.599868900 ## 19 0.38 0.590133700 ## 5 0.10 0.584885158 ## 20 0.40 0.583246611 ## 21 0.42 0.568352008 ## 4 0.08 0.560612633 ## 22 0.44 0.554271903 ## 23 0.46 0.541258844 ## 24 0.48 0.529804439 ## 3 0.06 0.522354048 ## 25 0.50 0.518221258 ## 26 0.52 0.504813542 ## 27 0.54 0.491698473 ## 28 0.56 0.479986567 ## 29 0.58 0.466757790 ## 2 0.04 0.454656791 ## 30 0.60 0.449933373 ## 31 0.62 0.438300082 ## 32 0.64 0.417604032 ## 33 0.66 0.400863236 ## 34 0.68 0.378422900 ## 35 0.70 0.358823982 ## 1 0.02 0.339623018 ## 36 0.72 0.336704746 ## 37 0.74 0.320134563 ## 38 0.76 0.292849283 ## 39 0.78 0.271079599 ## 40 0.80 0.237445887 ## 41 0.82 0.216821812 ## 42 0.84 0.193043596 ## 43 0.86 0.164350199 ## 44 0.88 0.140302731 ## 45 0.90 0.117638351 ## 46 0.92 0.092358334 ## 47 0.94 0.065594905 ## 48 0.96 0.035745887 ## 49 0.98 0.005821626 # Confusion matrix for train using Youden&#39;s Index optimal cut off train$classification = ifelse(train$p_hat &gt;= 0.2, 1, 0) confusionMatrix(train$over_50k, factor(train$classification)) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 19804 6194 ## 1 1011 7180 ## ## Accuracy : 0.7893 ## 95% CI : (0.7849, 0.7936) ## No Information Rate : 0.6088 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.5246 ## ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Sensitivity : 0.9514 ## Specificity : 0.5369 ## Pos Pred Value : 0.7618 ## Neg Pred Value : 0.8766 ## Prevalence : 0.6088 ## Detection Rate : 0.5793 ## Detection Prevalence : 0.7604 ## Balanced Accuracy : 0.7441 ## ## &#39;Positive&#39; Class : 0 ## AUROC # Evaluate model using AUROC train$p_hat &lt;- predict(logit.model, type = &quot;response&quot;) plotROC(train$over_50k, train$p_hat) # 0.902 AUROC 3.5 Test training cut off on validation # Make predictions on validation set validation$p_hat = predict(logit.model, newdata = validation, type = &#39;response&#39;) # Confusion Matrix using Youdens cutoff validation$classification = ifelse(validation$p_hat &gt;= 0.2, 1, 0) confusionMatrix(validation$over_50k, factor(validation$classification)) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 2794 880 ## 1 165 1045 ## ## Accuracy : 0.786 ## 95% CI : (0.7743, 0.7975) ## No Information Rate : 0.6059 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.5209 ## ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Sensitivity : 0.9442 ## Specificity : 0.5429 ## Pos Pred Value : 0.7605 ## Neg Pred Value : 0.8636 ## Prevalence : 0.6059 ## Detection Rate : 0.5721 ## Detection Prevalence : 0.7523 ## Balanced Accuracy : 0.7435 ## ## &#39;Positive&#39; Class : 0 ## # Get concordance Concordance(validation$over_50k, validation$p_hat) ## $Concordance ## [1] 0.9007185 ## ## $Discordance ## [1] 0.09928153 ## ## $Tied ## [1] 0 ## ## $Pairs ## [1] 4445540 # Evaluate model using AUROC plotROC(validation$over_50k, validation$p_hat) # 0.899 AUROC "],["create-xgboost.html", "Chapter 4 Create XGBoost 4.1 Tuning an XGBoost nrounds parameter - 11 was lowest 4.2 Tuning through caret 4.3 Variable importance 4.4 ROC Curve and AUC", " Chapter 4 Create XGBoost 4.1 Tuning an XGBoost nrounds parameter - 11 was lowest 4.2 Tuning through caret eta = .9 and subsample = .25, max tree depth = 10 4.3 Variable importance xgb &lt;- xgboost(data = train_x, label = train_y, subsample = .25, nrounds = 11, eta = 0.9, max_depth = 10) ## [1] train-rmse:0.340135 ## [2] train-rmse:0.336631 ## [3] train-rmse:0.333233 ## [4] train-rmse:0.333880 ## [5] train-rmse:0.336040 ## [6] train-rmse:0.337866 ## [7] train-rmse:0.339267 ## [8] train-rmse:0.339087 ## [9] train-rmse:0.339663 ## [10] train-rmse:0.341031 ## [11] train-rmse:0.340575 xgb.importance(feature_names = colnames(train_x), model = xgb) ## Feature Gain Cover Frequency ## 1: marital_statusMarried-civ-spouse 0.2273600229 0.0527439508 0.051390356 ## 2: capital_gain_indicator 0.0618545038 0.0394778043 0.055614220 ## 3: occupationProf-specialty 0.0517327803 0.0403882367 0.022175290 ## 4: occupationExec-managerial 0.0512482996 0.0218074816 0.018303414 ## 5: education_levelBachelors 0.0429543688 0.0163416706 0.030271031 ## 6: hours_week_bin2 0.0362576470 0.0340945649 0.048926434 ## 7: age_bin2 0.0299032012 0.0478357662 0.051742344 ## 8: capital_loss_indicator 0.0298984616 0.0275102839 0.033438930 ## 9: hours_week_bin1 0.0291770053 0.0246567381 0.052446322 ## 10: age_bin1 0.0259130395 0.0218868362 0.062653995 ## 11: sexMale 0.0256835788 0.0163491771 0.048574446 ## 12: workclassSelf-emp-not-inc 0.0211352929 0.0268625794 0.020415347 ## 13: age_bin3 0.0208044869 0.0220037232 0.034142907 ## 14: country_bin 0.0194847678 0.0111836264 0.029215065 ## 15: education_levelHS-grad 0.0176945331 0.0163588283 0.023231257 ## 16: marital_statusNever-married 0.0165244621 0.0109123197 0.027455121 ## 17: workclassLocal-gov 0.0162854398 0.0306522942 0.024287223 ## 18: education_levelSome-college 0.0162270007 0.0139127787 0.022879268 ## 19: workclassPrivate 0.0157738781 0.0122988792 0.032030975 ## 20: education_levelMasters 0.0152197343 0.0338028834 0.020415347 ## 21: workclassSelf-emp-inc 0.0150251453 0.0466561719 0.017951426 ## 22: workclassState-gov 0.0140412321 0.0152167665 0.019711369 ## 23: education_levelDoctorate 0.0132824861 0.0417415530 0.011263640 ## 24: occupationSales 0.0127450992 0.0271499715 0.014431538 ## 25: raceBlack 0.0118962703 0.0120275725 0.018655403 ## 26: occupationTech-support 0.0116405943 0.0176499479 0.009855685 ## 27: raceAsian-Pac-Islander 0.0109917840 0.0292689518 0.015135516 ## 28: education_levelAssoc-acdm 0.0109646437 0.0056985129 0.016895459 ## 29: occupationProtective-serv 0.0106562593 0.0461242821 0.009855685 ## 30: raceWhite 0.0101277694 0.0084920066 0.012319606 ## 31: occupationCraft-repair 0.0098904895 0.0180960490 0.012671595 ## 32: education_levelAssoc-voc 0.0091385794 0.0299638401 0.015135516 ## 33: education_levelProf-school 0.0090272681 0.0240519279 0.009151707 ## 34: occupationFarming-fishing 0.0071400388 0.0167695416 0.007039775 ## 35: education_level7th-8th 0.0070718397 0.0048910269 0.005631820 ## 36: occupationAdm-clerical 0.0066976601 0.0144318001 0.013023583 ## 37: occupationOther-service 0.0062356669 0.0114002428 0.009503696 ## 38: occupationTransport-moving 0.0062105558 0.0135224402 0.007743752 ## 39: education_level9th 0.0053061415 0.0122913727 0.005279831 ## 40: occupationMachine-op-inspct 0.0052943682 0.0139181404 0.007391763 ## 41: marital_statusMarried-spouse-absent 0.0051963107 0.0033564820 0.007391763 ## 42: marital_statusSeparated 0.0048160845 0.0024728586 0.008095741 ## 43: marital_statusWidowed 0.0043967105 0.0031784705 0.006687786 ## 44: education_level11th 0.0038172565 0.0078507363 0.006687786 ## 45: marital_statusMarried-AF-spouse 0.0038155091 0.0305868803 0.003871876 ## 46: occupationHandlers-cleaners 0.0033002506 0.0094732146 0.004927842 ## 47: workclassUnknown 0.0030600390 0.0027323694 0.004575854 ## 48: education_level5th-6th 0.0024772236 0.0031387932 0.003519887 ## 49: education_level12th 0.0023901030 0.0019731396 0.002463921 ## 50: raceOther 0.0019639058 0.0043344729 0.002463921 ## 51: education_levelEarly-Ed 0.0002502108 0.0004600418 0.001055966 ## Feature Gain Cover Frequency xgb.ggplot.importance(xgb.importance(feature_names = colnames(train_x), model = xgb)) 4.4 ROC Curve and AUC # get predictions # Prepare data for predict function validation_x &lt;- model.matrix(over_50k ~ ., data = validation)[, 3:53] validation_y &lt;- as.numeric(as.character(validation$over_50k)) p_hat_xgb &lt;- predict(xgb, newdata = validation_x, type = &quot;response&quot;) # create ROC object rocobj &lt;- roc(validation$over_50k, p_hat_xgb) ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases rocobj$auc # to get AUC - 0.816 ## Area under the curve: 0.8379 # create ROC plot with minimal theme ggroc(rocobj, colour = &#39;steelblue&#39;, size = 2) + ggtitle(paste0(&#39;XGBoost Model ROC Curve &#39;, &#39;(AUC = &#39;, round(rocobj$auc, 4), &#39;)&#39;)) + theme_minimal()+ labs(x=&quot;1-Specificity (FPR)&quot;,y=&quot;Sensitivity (TPR)&quot;)+geom_abline(intercept = 1.00, size = 0.5, linetype=&quot;dotted&quot;, color = &quot;red&quot;)+ coord_cartesian(xlim=c(1,0)) "],["conclusion-write-up.html", "Chapter 5 Conclusion / Write Up 5.1 Figure 1 5.2 Final AUROC Chart", " Chapter 5 Conclusion / Write Up Overview The goal of this project is to develop a model that predicts whether individuals, based on census variables, make over $50,000/year. I compared the predictive power of a logistic regression to an XGBoost model using the area under the ROC curve (AUROC). This statistic calculates each models ability to distinguish between people who make above $50,000/year from those who do not. The logistic regression model resulted in the higher AUROC, and was able to better predict who is likely to make above $50,000/year from census data. The final AUROC on the test data was 0.894. Methodology The first two steps were exploring each variable individually and binning continuous variables into categories. Each variable was then tested for quasi-complete separation. This is a problem when a subgroup of the predictor variable perfectly predicts the target variable outcome. Each subgroup with less than 5 observations was collapsed into a new, larger group. The data was split into a 70/20/10 training/validation/test split and each variable was tested for multi-collinearity to ensure no two variables are providing the same information in the model. Stepwise selection was used to identify which variables were important in predicting the target. The 13 important variables were then used in a forward selection process to identify any predictive interactions. For example, the selection process identified changes in the target variables relationship with hours worked each week when looking at different occupations. A logistic regression was built using these variables. The XGBoost was tuned and built using all census variables, and the most important variables were calculated using a gain statistic. Results A simple relationship between marital status and people who make over 50k can be pictured in Figure 1. This figure shows the large majority of people who make over 50k are married to civil spouses. In our census data, 85% of people who make over 50k are married to a civil spouse compared to only 33% of those who do not make over 50k. Furthermore, the XGBoost model found marital status to be the most important variable in predicting the target. The logistic regression was able to better predict people who make over $50,000/year using census variables. I recommend using a logistic regression moving forward to best predict the individuals that make over 50K using census data. Given more time for tuning, you might be able to challenge the predictive power using a future XGBoost model. 5.1 Figure 1 # Add color blind palette cbPalette = c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;) # Plot data ggplot(data = train) + geom_bar(mapping = aes(x = over_50k, fill = marital_status, color =)) + scale_fill_manual(values=cbPalette) + #scale_fill_discrete(labels = c(&quot;Divorced&quot;, &quot;Married- Armed Forces&quot;, &quot;Married- Civil Spouse&quot;, &quot;Married- Spouse Absent&quot;, &quot;Never Married&quot;, &quot;Separated&quot;, &quot;Widowed&quot;)) + labs(title=&quot;Marital Status over Earning Category&quot;, x =&quot;Earning Over 50k (0: No, 1: Yes)&quot;, y = &quot;Frequency&quot;, fill = &quot;Marital Status&quot;) + theme_minimal() 5.2 Final AUROC Chart # Make predictions on validation set test$p_hat = predict(logit.model, newdata = test, type = &#39;response&#39;) # Evaluate model using AUROC plotROC(test$over_50k, test$p_hat) # 0.894 AUROC This repo was initially generated from a bookdown template available here: https://github.com/jtr13/bookdown-template. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
